
# Stanford Machine Learning Course

This directory contains lectures and completed exercises for the _Stanford Machine Learning Course_ taught by Andrew Ng.
The exercises are solved in MatLab and the outline of each assignment are present in the respective exercise folders.

## Lectures

* Lecture 1: quick overview of machine learning
* Lecture 2: linear regression with one variable, introduction to cost function, gradient descent
* Lecture 3: basic review of linear algebra (matrix multiplication, transposition, inverse...)
* Lecture 4: linear regression with multiple variables, feature scaling, polynomial regression, normal equation
* Lecture 5: very short slides on advantage of vectorized implementation
* Lecture 6: logistic regression, sigmoid function and logistic cost function, gradient descent, multi-class classification (one vs all)
* Lecture 7: overfitting and introduction to regularization, regularized logistic regression
* Lecture 8: introduction to neural networks, activation units, bias units...
* Lecture 9: NN cost function, backpropagation, random initialization
* Lecture 10: evaluating and optmizing hypotheses, train/xvalidation/test sets, bias vs variance, regularization, learning curves
* Lecture 11: error analysis and metrics, precision vs recall


## Exercises:

* machine-learning-ex1: simple implementation of linear regression with one and more variables using gradient descent
* machine-learning-ex2: logistic regression on two different datasets. Uses fminunc, polynomial feature mapping, computes decision boundary
* machine-learning-ex3: multi-class classification using neural networks. Uses handwritten digits dataset, does not include backpropagation
* machine-learning-ex4: again handwritten digits dataset but here we also implement backpropagation. Also regularization, gradient checking, uses fmincg and displays hidden layer
* machine-learning-ex5: exercises on diagnosing bias vs variance, impact of regularization parameter choice, plotting learning curves, usage of cross-validation set

